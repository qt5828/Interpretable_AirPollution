{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED_VALUE = 100\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "torch.manual_seed(SEED_VALUE)\n",
    "torch.cuda.manual_seed(SEED_VALUE)\n",
    "torch.cuda.manual_seed_all(SEED_VALUE)\n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f340337d310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    \n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# city pollution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_data = pd.read_csv(\"./data/gams_indoor.csv\")\n",
    "\n",
    "\n",
    "DROP_ONEHOT = True\n",
    "SEQ_LENGTH = 7\n",
    "\n",
    "\n",
    "if DROP_ONEHOT:\n",
    "  INPUT_DIM = 2\n",
    "# else:\n",
    "#   INPUT_DIM = 29\n",
    "\n",
    "HIDDEN_DIM = 32\n",
    "LAYER_DIM = 3\n",
    "\n",
    "\n",
    "normalization_type = 'mean_std' # 'max', mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:                          ts    co2  humidity  pm10  pm25  temperature    voc\n",
      "0       2016-11-21 00:47:03  708.0     72.09  10.2   9.0        20.83  0.062\n",
      "1       2016-11-21 00:48:03  694.0     70.95  10.9  10.1        21.01  0.062\n",
      "2       2016-11-21 00:49:03  693.0     69.12  10.2   9.9        21.20  0.062\n",
      "3       2016-11-21 00:50:03  692.0     68.83   9.6   9.6        21.37  0.062\n",
      "4       2016-11-21 00:51:03  690.0     68.60   9.4   8.4        21.49  0.062\n",
      "...                     ...    ...       ...   ...   ...          ...    ...\n",
      "108074  2017-03-09 14:22:02  626.0     33.61  37.8  33.9        24.16  0.062\n",
      "108075  2017-03-09 14:23:02  627.0     33.65  35.9  33.8        24.15  0.062\n",
      "108076  2017-03-09 14:24:02  625.0     33.65  37.3  33.2        24.14  0.062\n",
      "108077  2017-03-09 14:25:02  625.0     33.56  37.0  33.4        24.18  0.062\n",
      "108078  2017-03-09 14:26:02  624.0     33.54  38.5  34.1        24.21  0.063\n",
      "\n",
      "[108079 rows x 7 columns]\n",
      "Test data:                          ts     co2  humidity  pm10  pm25  temperature    voc\n",
      "108079  2017-03-09 14:27:02   623.0     33.46  37.4  34.1        24.27  0.062\n",
      "108080  2017-03-09 14:28:02   622.0     33.46  40.1  35.2        24.26  0.062\n",
      "108081  2017-03-09 14:30:02   617.0     33.46  36.5  32.1        24.24  0.065\n",
      "108082  2017-03-09 14:31:02   618.0     33.54  34.3  31.5        24.22  0.062\n",
      "108083  2017-03-09 14:32:02   615.0     33.52  35.5  32.4        24.20  0.063\n",
      "...                     ...     ...       ...   ...   ...          ...    ...\n",
      "135094  2017-03-28 09:26:03  1359.0     39.55   6.3   4.4        26.93  0.148\n",
      "135095  2017-03-28 09:27:03  1350.0     39.49   5.6   4.2        26.92  0.152\n",
      "135096  2017-03-28 09:28:03  1353.0     39.42   6.3   4.6        26.91  0.147\n",
      "135097  2017-03-28 09:29:03  1348.0     39.55   5.7   4.3        26.92  0.148\n",
      "135098  2017-03-28 09:30:03  1363.0     39.55   5.8   4.2        26.90  0.139\n",
      "\n",
      "[27020 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 시간 순서대로 정렬합니다.\n",
    "time_series_data = time_series_data.sort_values(by='ts')\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터의 기간을 결정합니다.\n",
    "train_end_time = '2017-03-09 14:26:02'\n",
    "test_start_time = '2017-03-09 14:27:02'\n",
    "\n",
    "# 기준 시간을 기준으로 데이터를 분할합니다.\n",
    "train_data = time_series_data[time_series_data['ts'] <= train_end_time]\n",
    "test_data = time_series_data[time_series_data['ts'] >= test_start_time]\n",
    "\n",
    "print(\"Train data:\", train_data)\n",
    "print(\"Test data:\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        humidity  temperature    co2\n",
      "0          72.09        20.83  708.0\n",
      "1          70.95        21.01  694.0\n",
      "2          69.12        21.20  693.0\n",
      "3          68.83        21.37  692.0\n",
      "4          68.60        21.49  690.0\n",
      "...          ...          ...    ...\n",
      "108074     33.61        24.16  626.0\n",
      "108075     33.65        24.15  627.0\n",
      "108076     33.65        24.14  625.0\n",
      "108077     33.56        24.18  625.0\n",
      "108078     33.54        24.21  624.0\n",
      "\n",
      "[108079 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "features = ['humidity','temperature']\n",
    "SELECTED_COLUMN = \"co2\" # ['co2','pm10','pm25','voc']\n",
    "train_data = train_data[features + [SELECTED_COLUMN]]\n",
    "test_data = test_data[features + [SELECTED_COLUMN]]\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GamsIndoor(torch.utils.data.Dataset):\n",
    "  def __init__(self, data, selected_column, seq_length):\n",
    "    self.selected_column = selected_column\n",
    "    self.data = data \n",
    "    self.seq_length = seq_length\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    seq = self.data[features][idx:idx+self.seq_length]\n",
    "    target = self.data[SELECTED_COLUMN][idx:idx+self.seq_length]\n",
    "    return torch.tensor(seq.values, dtype=torch.float32), torch.tensor(target.values, dtype=torch.float32)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data) - self.seq_length\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that implement the look_ahead mask for masking future time steps. \n",
    "def create_look_ahead_mask(size, device):\n",
    "    mask = torch.ones((size, size), device=device)\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "    return mask  # (size, size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch\n",
    "\n",
    "device=\"cuda\"\n",
    "\n",
    "# Evaluation\n",
    "def evaluation(testLoader, model, model_name, LUR, SELECTED_COLUMN, mask=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    mse_list = []\n",
    "    total_se = 0.0\n",
    "    total_pe = 0.0\n",
    "    total_valid = 0.0\n",
    "\n",
    "    for x_val, y_val in testLoader:\n",
    "        x_val, y_val = [t.cuda().float() for t in (x_val, y_val)]\n",
    "        \n",
    "        if mask:\n",
    "            masking = create_look_ahead_mask(x_val.shape[1], device)\n",
    "            out, _ = model(x_val.to(device), masking)\n",
    "        else:\n",
    "            out = model(x_val.to(device))\n",
    "\n",
    "        if LUR :\n",
    "            ytrue = y_val.squeeze().cpu().numpy()\n",
    "            ypred = out.squeeze().cpu().detach().numpy()\n",
    "        else:\n",
    "            ytrue = y_val.squeeze().cpu().numpy()\n",
    "            ypred = out.squeeze().cpu().detach().numpy()\n",
    "        true_valid = np.isnan(ytrue) != 1\n",
    "        ytrue = ytrue[true_valid] #np.nan_to_num(ytrue, 0)\n",
    "        ypred = ypred[true_valid]\n",
    "\n",
    "        se = (ytrue - ypred)**2 # np.square(ytrue - ypred)\n",
    "        pe = np.abs((ytrue - ypred) / (ytrue + 0.0001))\n",
    "        total_se += np.sum(se)\n",
    "        total_pe += np.sum(pe)\n",
    "        total_valid += np.sum(true_valid)\n",
    "\n",
    "    eval_mse = total_se / total_valid # np.mean(se) # \n",
    "    eval_mape = total_pe / total_valid # np.mean(pe) # \n",
    "    print('valid samples:', total_valid)\n",
    "    print('Eval MSE: ', eval_mse)\n",
    "    print('Eval RMSE: {}: '.format(SELECTED_COLUMN), np.sqrt(eval_mse))\n",
    "    print('Eval MAPE: {}: '.format(SELECTED_COLUMN), eval_mape*100)\n",
    "    \n",
    "    return eval_mse, eval_mape*100\n",
    "\n",
    "\n",
    "# Train\n",
    "def train(trainLoader, testLoader, model, model_name, SELECTED_COLUMN, mask=False, LUR=False, l1=False, l2=False):\n",
    "\n",
    "    lr = 0.001\n",
    "    n_epochs = 10   \n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # LUR\n",
    "    if LUR:\n",
    "        print(\"set l1,l2 loss\")\n",
    "        l1_lmbda = 0.01\n",
    "        l1_lmbda = torch.FloatTensor([l1_lmbda]).cuda()\n",
    "        l1_reg = torch.tensor(0., requires_grad=True).to(device)\n",
    "        l2_lmbda = 0.01\n",
    "        l2_lmbda = torch.FloatTensor([l2_lmbda]).cuda()\n",
    "        l2_reg = torch.tensor(0., requires_grad=True).to(device)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "    # DL\n",
    "    else:\n",
    "        print(\"set SoftDTW loss\")\n",
    "        lmbda = 0.5\n",
    "        dtw_loss = SoftDTW(use_cuda=True, gamma=0.1)\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "      \n",
    "    print('Start ' + model_name + ' training')\n",
    "    best_mse = 2000.0\n",
    "    mape = 2000.0\n",
    "    best_model = None\n",
    "    \n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # print(\"start epoch\")\n",
    "        epoch_loss = 0\n",
    "        batch_idx = 0\n",
    "        bar = tqdm(trainLoader)\n",
    "        # print(\"start tqdm\")\n",
    "        model.train()\n",
    "        # print(\"start batch before\")\n",
    "        for x_batch, y_batch in bar:\n",
    "            # print(\"start batch\")\n",
    "            model.train()\n",
    "            x_batch = x_batch.cuda().float()\n",
    "            y_batch = y_batch.cuda().float()\n",
    "\n",
    "            # print(\"start mask\")\n",
    "            if mask==True:\n",
    "                masking = create_look_ahead_mask(x_batch.shape[1], device)\n",
    "                out, _ = model(x_batch.to(device), masking)\n",
    "            else :\n",
    "                out = model(x_batch.to(device))\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # print(\"start loss\")\n",
    "            if LUR:\n",
    "                # LASSO\n",
    "                if l1==True and l2==False:\n",
    "                    l1_reg = torch.norm(model.linear.weight, p=1)\n",
    "                    loss = criterion(out, y_batch.unsqueeze(2)) + l1_lmbda * l1_reg\n",
    "                # Ridge\n",
    "                elif l1==False and l2==True:\n",
    "                    l2_reg = torch.norm(model.linear.weight, p=2)\n",
    "                    loss = criterion(out, y_batch.unsqueeze(2)) + l2_lmbda * l2_reg\n",
    "                # Elastic\n",
    "                elif l1==True and l2==True:\n",
    "                    l1_reg = torch.norm(model.linear.weight, p=1)\n",
    "                    l2_reg = torch.norm(model.linear.weight, p=2)\n",
    "                    loss = criterion(out, y_batch.unsqueeze(2)) + l1_lmbda * l1_reg + l2_lmbda * l2_reg\n",
    "                # OLS\n",
    "                else:\n",
    "                    loss = criterion(out, y_batch.unsqueeze(2))\n",
    "            else:\n",
    "                # print(out.shape)\n",
    "                # print(y_batch.shape)\n",
    "                # print(y_batch.unsqueeze(2).shape)\n",
    "                loss = criterion(out, y_batch.unsqueeze(2)) + lmbda * dtw_loss(out.cuda(),y_batch.unsqueeze(2).cuda()).mean()\n",
    "\n",
    "            epoch_loss = (epoch_loss*batch_idx + loss.item())/(batch_idx+1)\n",
    "            loss.backward(retain_graph=True)\n",
    "            opt.step()\n",
    "\n",
    "            bar.set_description(str(epoch_loss))\n",
    "            batch_idx += 1\n",
    "\n",
    "        eval_mse, eval_mape = evaluation(testLoader, model, model_name, LUR, SELECTED_COLUMN, mask)\n",
    "        \n",
    "\n",
    "        if eval_mse < best_mse:\n",
    "            best_model = deepcopy(model)\n",
    "            best_mse = eval_mse\n",
    "            mape = eval_mape\n",
    "            torch.save(best_model.state_dict(), \"./save_gams/\"+SELECTED_COLUMN+\"/\"+model_name+\".pth\")\n",
    "      \n",
    "    print(model_name)   \n",
    "    print(\"Best MSE :\", best_mse)\n",
    "    print(\"RMSE :\", np.sqrt(best_mse))\n",
    "    print(\"MAPE :\", mape)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from loss_utils import *\n",
    "\n",
    "\n",
    "train_data = GamsIndoor(train_data, SELECTED_COLUMN, SEQ_LENGTH)\n",
    "test_data = GamsIndoor(test_data, SELECTED_COLUMN, SEQ_LENGTH)\n",
    "trainLoader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4, worker_init_fn=seed_worker, generator=g)\n",
    "testLoader = DataLoader(test_data, batch_size=4096, shuffle=False, num_workers=4, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set SoftDTW loss\n",
      "Start CosFormer training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2760724.3552397857: 100%|██████████| 3378/3378 [02:55<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649655.8427423832\n",
      "Eval RMSE: co2:  806.0123092995436\n",
      "Eval MAPE: co2:  99.62579814414752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2759077.7832297278: 100%|██████████| 3378/3378 [03:00<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649366.2443585363\n",
      "Eval RMSE: co2:  805.832640415202\n",
      "Eval MAPE: co2:  99.58898034709478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2759545.333444346: 100%|██████████| 3378/3378 [03:01<00:00, 18.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649793.7075376406\n",
      "Eval RMSE: co2:  806.0978275232111\n",
      "Eval MAPE: co2:  99.64326865107277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2759150.4649200733: 100%|██████████| 3378/3378 [02:59<00:00, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649329.9721298211\n",
      "Eval RMSE: co2:  805.8101340451242\n",
      "Eval MAPE: co2:  99.58437050480985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2758053.483792185: 100%|██████████| 3378/3378 [03:02<00:00, 18.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649327.5568694439\n",
      "Eval RMSE: co2:  805.8086353902171\n",
      "Eval MAPE: co2:  99.58405856836127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2758200.202172142: 100%|██████████| 3378/3378 [02:59<00:00, 18.79it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649327.5568694439\n",
      "Eval RMSE: co2:  805.8086353902171\n",
      "Eval MAPE: co2:  99.58405753545911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2758019.530935475: 100%|██████████| 3378/3378 [02:54<00:00, 19.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649327.5568694439\n",
      "Eval RMSE: co2:  805.8086353902171\n",
      "Eval MAPE: co2:  99.58405753545911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2758233.5276050866: 100%|██████████| 3378/3378 [02:52<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649327.5568694439\n",
      "Eval RMSE: co2:  805.8086353902171\n",
      "Eval MAPE: co2:  99.58405753545911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2758002.901568973: 100%|██████████| 3378/3378 [02:51<00:00, 19.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649327.5568694439\n",
      "Eval RMSE: co2:  805.8086353902171\n",
      "Eval MAPE: co2:  99.58405753545911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2758537.575266434: 100%|██████████| 3378/3378 [02:52<00:00, 19.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  649327.5622848258\n",
      "Eval RMSE: co2:  805.808638750433\n",
      "Eval MAPE: co2:  99.58406166706772\n",
      "CosFormer\n",
      "Best MSE : 2000.0\n",
      "RMSE : 44.721359549995796\n",
      "MAPE : 2000.0\n",
      "\n",
      "set SoftDTW loss\n",
      "Start CosSquareFormer training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2746409.6968250386: 100%|██████████| 3378/3378 [02:52<00:00, 19.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645816.5210189803\n",
      "Eval RMSE: co2:  803.6271032132878\n",
      "Eval MAPE: co2:  99.13680470811673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2743322.218176438: 100%|██████████| 3378/3378 [02:51<00:00, 19.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645855.0406312305\n",
      "Eval RMSE: co2:  803.6510689542014\n",
      "Eval MAPE: co2:  99.14172442104595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2743298.642724986: 100%|██████████| 3378/3378 [02:51<00:00, 19.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645819.3207714804\n",
      "Eval RMSE: co2:  803.6288451589331\n",
      "Eval MAPE: co2:  99.1371662238684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2742993.7388987644: 100%|██████████| 3378/3378 [02:51<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645828.1478441597\n",
      "Eval RMSE: co2:  803.6343371485316\n",
      "Eval MAPE: co2:  99.13829518591578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2743317.8588291924: 100%|██████████| 3378/3378 [02:50<00:00, 19.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645813.3367743574\n",
      "Eval RMSE: co2:  803.6251220403437\n",
      "Eval MAPE: co2:  99.13640187627915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2743126.192421549: 100%|██████████| 3378/3378 [02:48<00:00, 20.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645827.9041519691\n",
      "Eval RMSE: co2:  803.6341855296906\n",
      "Eval MAPE: co2:  99.13825490273202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2743010.902679098: 100%|██████████| 3378/3378 [02:48<00:00, 20.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645820.1330787821\n",
      "Eval RMSE: co2:  803.6293505583169\n",
      "Eval MAPE: co2:  99.13726228376814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2743116.018946122: 100%|██████████| 3378/3378 [02:50<00:00, 19.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645866.4779180394\n",
      "Eval RMSE: co2:  803.6581847514772\n",
      "Eval MAPE: co2:  99.14318287887842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2742936.5057726507: 100%|██████████| 3378/3378 [02:50<00:00, 19.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645824.5736920319\n",
      "Eval RMSE: co2:  803.6321134026638\n",
      "Eval MAPE: co2:  99.13783657736222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2742972.6541592674: 100%|██████████| 3378/3378 [02:51<00:00, 19.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  645826.0954143772\n",
      "Eval RMSE: co2:  803.6330601800657\n",
      "Eval MAPE: co2:  99.13802973006383\n",
      "CosSquareFormer\n",
      "Best MSE : 2000.0\n",
      "RMSE : 44.721359549995796\n",
      "MAPE : 2000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # RNN\n",
    "# RNNmodel = RNN(1, INPUT_DIM, HIDDEN_DIM, LAYER_DIM).to(device)\n",
    "# train(trainLoader, testLoader, RNNmodel, \"RNN\", SELECTED_COLUMN)\n",
    "# # LSTM\n",
    "# LSTMmodel = LSTM(1, INPUT_DIM, HIDDEN_DIM, LAYER_DIM).to(device)\n",
    "# train(trainLoader, testLoader, LSTMmodel, \"LSTM\", SELECTED_COLUMN)\n",
    "# # # BiLSTM\n",
    "# # # BiLSTMmodel = LSTM(1, INPUT_DIM+1, HIDDEN_DIM, LAYER_DIM, bidirectional=True).to(device)\n",
    "# # # train(trainLoader, testLoader, BiLSTMmodel, \"BiLSTM\", SELECTED_COLUMN)\n",
    "# # # TransLSTM\n",
    "# # TransLSTMmodel = TransLSTM(num_layers=3, D=16, H=5, hidden_mlp_dim=32, inp_features=2, out_features=1, dropout_rate=0.2, LSTM_module = LSTM(1, INPUT_DIM, HIDDEN_DIM, LAYER_DIM, bidirectional = False).to(device), attention_type='regular').to(device) # cosine_square, cosine, regular # 6L, 12H\n",
    "# # train(trainLoader, testLoader, TransLSTMmodel, \"TransLSTM\", SELECTED_COLUMN, mask=True)\n",
    "# # Transformer\n",
    "# Transmodel = Transformer(num_layers=6, D=16, H=10, hidden_mlp_dim=32, inp_features=2, out_features=1, dropout_rate=0.1, attention_type='regular', SL=SEQ_LENGTH).to(device) # cosine_square, cosine, regular # 6L, 12H\n",
    "# train(trainLoader, testLoader, Transmodel, \"Transformer\", SELECTED_COLUMN, mask=True)\n",
    "# CosFormer\n",
    "TransCosModel = Transformer(num_layers=6, D=16, H=10, hidden_mlp_dim=32, inp_features=2, out_features=1, dropout_rate=0.1, attention_type='cosine', SL=SEQ_LENGTH).to(device) # cosine_square, cosine, regular # 6L, 12\n",
    "train(trainLoader, testLoader, TransCosModel, \"CosFormer\", SELECTED_COLUMN, mask=True)\n",
    "# CosSquareFormer\n",
    "TransCosSquare = Transformer(num_layers=6, D=16, H=10, hidden_mlp_dim=32, inp_features=2, out_features=1, dropout_rate=0.1, attention_type='cosine_square', SL=SEQ_LENGTH).to(device) # cosine_square, cosine, regular # 6L, 12H\n",
    "train(trainLoader, testLoader, TransCosModel, \"CosSquareFormer\", SELECTED_COLUMN, mask=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set l1,l2 loss\n",
      "Start OLS training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "478744.1397461514: 100%|██████████| 3378/3378 [00:38<00:00, 88.00it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  391190.7879275058\n",
      "Eval RMSE: co2:  625.4524665612134\n",
      "Eval MAPE: co2:  61.80553082328747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "294420.77948420896: 100%|██████████| 3378/3378 [00:38<00:00, 87.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  239565.29036284116\n",
      "Eval RMSE: co2:  489.4540738034991\n",
      "Eval MAPE: co2:  28.831188484479696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186307.00617391037: 100%|██████████| 3378/3378 [00:38<00:00, 88.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  164647.27099650432\n",
      "Eval RMSE: co2:  405.7675085520085\n",
      "Eval MAPE: co2:  32.673580342103804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140752.2700770614: 100%|██████████| 3378/3378 [00:38<00:00, 87.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  146390.37737385705\n",
      "Eval RMSE: co2:  382.609954619397\n",
      "Eval MAPE: co2:  46.154809494006855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132116.0687398239: 100%|██████████| 3378/3378 [00:38<00:00, 88.30it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  145882.19251048437\n",
      "Eval RMSE: co2:  381.9452742350458\n",
      "Eval MAPE: co2:  50.053943314660664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131017.41888460227: 100%|██████████| 3378/3378 [00:38<00:00, 86.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  145196.57807087593\n",
      "Eval RMSE: co2:  381.0466875211959\n",
      "Eval MAPE: co2:  49.90319563604627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130155.1321568325: 100%|██████████| 3378/3378 [00:39<00:00, 85.67it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  144475.03663315545\n",
      "Eval RMSE: co2:  380.098719588945\n",
      "Eval MAPE: co2:  49.58605129482961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "129370.34139098578: 100%|██████████| 3378/3378 [00:38<00:00, 87.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  143801.9398490674\n",
      "Eval RMSE: co2:  379.21226226094984\n",
      "Eval MAPE: co2:  49.37061656986583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128482.54068605683: 100%|██████████| 3378/3378 [00:38<00:00, 88.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  143102.69760062615\n",
      "Eval RMSE: co2:  378.2891719315082\n",
      "Eval MAPE: co2:  48.94019126786177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127691.35710733978: 100%|██████████| 3378/3378 [00:39<00:00, 86.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  142459.87280198422\n",
      "Eval RMSE: co2:  377.43856824917117\n",
      "Eval MAPE: co2:  48.646576954019494\n",
      "OLS\n",
      "Best MSE : 2000.0\n",
      "RMSE : 44.721359549995796\n",
      "MAPE : 2000.0\n",
      "\n",
      "set l1,l2 loss\n",
      "Start LASSO training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "464198.4573249704: 100%|██████████| 3378/3378 [00:39<00:00, 85.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  377548.31694792456\n",
      "Eval RMSE: co2:  614.4496048887366\n",
      "Eval MAPE: co2:  59.25478826580191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284902.144872382: 100%|██████████| 3378/3378 [00:38<00:00, 88.53it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  231518.2127547054\n",
      "Eval RMSE: co2:  481.16339506939363\n",
      "Eval MAPE: co2:  27.10712941908592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181667.73133083124: 100%|██████████| 3378/3378 [00:38<00:00, 87.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid samples: 189091.0\n",
      "Eval MSE:  161912.90788033276\n",
      "Eval RMSE: co2:  402.3840303495316\n",
      "Eval MAPE: co2:  33.97879655372611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140517.93278773676:  95%|█████████▌| 3218/3378 [00:36<00:01, 88.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train(trainLoader, testLoader, OLS, \u001b[39m\"\u001b[39m\u001b[39mOLS\u001b[39m\u001b[39m\"\u001b[39m, SELECTED_COLUMN, LUR\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m LASSO \u001b[39m=\u001b[39m LinearRegression(input_dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m train(trainLoader, testLoader, LASSO, \u001b[39m\"\u001b[39;49m\u001b[39mLASSO\u001b[39;49m\u001b[39m\"\u001b[39;49m, SELECTED_COLUMN, LUR\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, l1\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      5\u001b[0m Ridge \u001b[39m=\u001b[39m LinearRegression(input_dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m train(trainLoader, testLoader, Ridge, \u001b[39m\"\u001b[39m\u001b[39mRidge\u001b[39m\u001b[39m\"\u001b[39m, SELECTED_COLUMN, LUR\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, l2\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[8], line 95\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainLoader, testLoader, model, model_name, SELECTED_COLUMN, mask, LUR, l1, l2)\u001b[0m\n\u001b[1;32m     93\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     94\u001b[0m \u001b[39m# print(\"start batch before\")\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, y_batch \u001b[39min\u001b[39;00m bar:\n\u001b[1;32m     96\u001b[0m     \u001b[39m# print(\"start batch\")\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     98\u001b[0m     x_batch \u001b[39m=\u001b[39m x_batch\u001b[39m.\u001b[39mcuda()\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1326\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1164\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[39m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39;49mloads(res)\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:297\u001b[0m, in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrebuild_storage_fd\u001b[39m(\u001b[39mcls\u001b[39m, df, size):\n\u001b[0;32m--> 297\u001b[0m     fd \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdetach()\n\u001b[1;32m    298\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m         storage \u001b[39m=\u001b[39m storage_from_cache(\u001b[39mcls\u001b[39m, fd_id(fd))\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/multiprocessing/resource_sharer.py:58\u001b[0m, in \u001b[0;36mDupFd.detach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mwith\u001b[39;00m _resource_sharer\u001b[39m.\u001b[39mget_connection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id) \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mreturn\u001b[39;00m reduction\u001b[39m.\u001b[39;49mrecv_handle(conn)\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/multiprocessing/reduction.py:189\u001b[0m, in \u001b[0;36mrecv_handle\u001b[0;34m(conn)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m'''Receive a handle over a local connection.'''\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39mwith\u001b[39;00m socket\u001b[39m.\u001b[39mfromfd(conn\u001b[39m.\u001b[39mfileno(), socket\u001b[39m.\u001b[39mAF_UNIX, socket\u001b[39m.\u001b[39mSOCK_STREAM) \u001b[39mas\u001b[39;00m s:\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mreturn\u001b[39;00m recvfds(s, \u001b[39m1\u001b[39;49m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/home/iknow/anaconda3/envs/ma/lib/python3.9/multiprocessing/reduction.py:157\u001b[0m, in \u001b[0;36mrecvfds\u001b[0;34m(sock, size)\u001b[0m\n\u001b[1;32m    155\u001b[0m a \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39marray(\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    156\u001b[0m bytes_size \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mitemsize \u001b[39m*\u001b[39m size\n\u001b[0;32m--> 157\u001b[0m msg, ancdata, flags, addr \u001b[39m=\u001b[39m sock\u001b[39m.\u001b[39;49mrecvmsg(\u001b[39m1\u001b[39;49m, socket\u001b[39m.\u001b[39;49mCMSG_SPACE(bytes_size))\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m msg \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ancdata:\n\u001b[1;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "OLS = LinearRegression(input_dim=2)\n",
    "train(trainLoader, testLoader, OLS, \"OLS\", SELECTED_COLUMN, LUR=True)\n",
    "LASSO = LinearRegression(input_dim=2)\n",
    "train(trainLoader, testLoader, LASSO, \"LASSO\", SELECTED_COLUMN, LUR=True, l1=True)\n",
    "Ridge = LinearRegression(input_dim=2)\n",
    "train(trainLoader, testLoader, Ridge, \"Ridge\", SELECTED_COLUMN, LUR=True, l2=True)\n",
    "Elastic = LinearRegression(input_dim=2)\n",
    "train(trainLoader, testLoader, Elastic, \"Elastic\", SELECTED_COLUMN, LUR=True, l1=True, l2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
